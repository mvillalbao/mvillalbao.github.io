<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Lab 3 | Matias Villalba </title> <meta name="author" content="Matias Villalba"> <meta name="description" content="Third lab assignment for the Causal AI course"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mvillalbao.github.io/projects/3_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Matias</span> Villalba </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/lectures/">Schedule </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Lab 3</h1> <p class="post-description">Third lab assignment for the Causal AI course</p> </header> <article> <p>The jupiter notebook file is available <a href="https://github.com/alexanderquispe/CausalAI-Course/blob/main/labs/replication_3/group3_lab3_python.ipynb" rel="external nofollow noopener" target="_blank">here</a></p> <h1 id="workgroup-3">Workgroup 3</h1> <p><strong>Group 3</strong>: Valerie Dube, Erzo Garay, Juan Marcos Guerrero y Mat√≠as Villalba,</p> <h2 id="1-neyman-orthogonality-proof">1. Neyman Orthogonality Proof</h2> \[\begin{align*} Y_{nx1} &amp;= \alpha D_{nx1} + W_{nxp}\beta_{px1} + \epsilon_{nx1} \\ \widetilde{Y}_{nx1} &amp;= Y_{nx1} - W_{nxp} X_{Yw_{px1}} \\ \widetilde{D}_{nx1} &amp;= D_{nx1} - W_{nxp} X_{Dw_{px1}} \\ \end{align*}\] <p>Where \(W\) equals a matrix composed by one variable in each column, \(X\) equals a vector of coefficients, \(n\) equals the number of observations, and \(p\) equals the number of confounders.</p> \[\begin{align*} M(a,\eta) &amp;= E[(\widetilde{Y}_{nx1}(\eta_{1}) - a\widetilde{D}(\eta_{2})_{nx1})'(\widetilde{D}(\eta_{2})_{nx1})]=0 \\ \frac{\partial a}{\partial \eta} &amp;= -[\frac{\partial M}{\partial a}(\alpha,\eta_{0})]^{-1}[\frac{\partial M}{\partial \eta}(\alpha,\eta_{0})] \\ \frac{\partial M}{\partial \eta}(\alpha,\eta_{0})&amp;=\frac{\partial M}{\partial \eta_{1}}(\alpha,X_{Yw},X_{Dw})+\frac{\partial M}{\partial \eta_{2}}(\alpha,X_{Yw},X_{Dw})\\ S_{1}&amp;=\frac{\partial M}{\partial \eta_{1}}(\alpha,X_{Yw},X_{Dw}), S_{2}=\frac{\partial M}{\partial \eta_{2}}(\alpha,X_{Yw},X_{Dw}) \end{align*}\] <h1 id="demonstration-1">Demonstration 1:</h1> <p>Given the general formula, before using \((\alpha,X_{Yw},X_{Dw})\): \(\widetilde{Y}_{nx1}=Y_{nx1}-W_{nxp}\eta_{1_{px1}}\), \(\widetilde{D}_{nx1}=D_{nx1}-W_{nxp}\eta_{2_{px1}}\):</p> \[\begin{align*} S_{1}&amp;=\frac{\partial M}{\partial \eta_{1}}|_{(\alpha,W_{Yw},W_{Dw})}\\ &amp;=\frac{\partial E[(\widetilde{Y}_{nx1}(\eta_{1})-a\widetilde{D}(\eta_{2})_{nx1})'(\widetilde{D}(\eta_{2})_{nx1})]}{\partial \eta_{1}}|_{(\alpha,W_{Yw},W_{Dw})}=\frac{\partial E[Y_{nx1}-W_{nxp}\eta_{1_{px1}}-aD_{nx1}+aW_{nxp}\eta_{2_{px1}})'(D_{nx1}-W_{nxp}\eta_{2_{px1}})}{\partial \eta_{1}}|_{(\alpha,W_{Yw},W_{Dw})} \end{align*}\] <p>Substituting \((\alpha,W_{Yw},W_{Dw})\) in \((a,\eta_{1},\eta_{2})\):</p> \[\begin{align*} &amp;=\frac{\partial E[(\widetilde{Y}_{nx1}(\eta_{1})-a\widetilde{D}(\eta_{2})_{nx1})'(\widetilde{D}(\eta_{2})_{nx1})]}{\partial \eta_{1}}|_{(\alpha,W_{Yw},W_{Dw})}=E[(W_{nxp})'(D_{nx1}-W_{n*p}\eta_{2_{px1}})]|_{(\alpha,W_{Yw},W_{Dw})}\\ &amp;=E[(W_{nxp})'(D_{nx1}-W_{n*p}X_{Dw_{px1}})]\\ &amp;=E[W'_{pxn}D_{nx1}-W'_{pxn}W_{nxp}(W'_{pxn}W_{nxp})^{-1}(W'_{pxn}D_{nx1})]\\ &amp;=E[W'_{pxn}D_{nx1}-I_{pxp}(W'_{pxn}D_{nx1})]=E[W'_{pxn}D_{nx1}-W'_{pxn}D_{nx1}]=E[0]\\ S_{1}&amp;=0 \end{align*}\] <h2 id="2-code-section">2. Code Section</h2> <h3 id="21-orthogonal-learning">2.1. Orthogonal Learning</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">hdmpy</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">colors</span>
<span class="kn">from</span> <span class="n">multiprocess</span> <span class="kn">import</span> <span class="n">Pool</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">time</span>
</code></pre></div></div> <h3 id="simulation-design">Simulation Design</h3> <p>We are going to simulate 3 different trials to show the properties we talked about orthogonal learning.</p> <p>For that we first define a function that runs a single observation of our simulation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">simulate_once</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>  <span class="c1"># Ensure numpy is imported within the function
</span>    <span class="kn">import</span> <span class="n">hdmpy</span>
    <span class="kn">import</span> <span class="n">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="p">)</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">p</span> <span class="p">,</span> <span class="mi">1</span> <span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="p">)</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">p</span> <span class="p">,</span> <span class="mi">1</span> <span class="p">)</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sd</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span> <span class="n">mean</span> <span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">p</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="p">)</span>

    <span class="n">D</span> <span class="o">=</span> <span class="p">(</span> <span class="n">X</span> <span class="o">@</span> <span class="n">gamma</span> <span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span> <span class="n">mean</span> <span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1</span> <span class="p">)</span><span class="o">/</span><span class="mi">4</span> <span class="c1"># We reshape because in r when we sum a vecto with a matrix it sum by column
</span>    <span class="n">Y</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">D</span> <span class="o">+</span> <span class="p">(</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta</span> <span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span> <span class="n">mean</span> <span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1</span> <span class="p">)</span>

    <span class="c1"># single selection method
</span>    <span class="n">r_lasso_estimation</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="p">.</span><span class="nf">rlasso</span><span class="p">(</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span> <span class="n">D</span> <span class="p">,</span> <span class="n">X</span> <span class="p">)</span> <span class="p">,</span> <span class="n">axis</span>  <span class="o">=</span>  <span class="mi">1</span> <span class="p">)</span> <span class="p">,</span> <span class="n">Y</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="bp">True</span> <span class="p">)</span> <span class="c1"># Regress main equation by lasso
</span>    <span class="n">coef_array</span> <span class="o">=</span> <span class="n">r_lasso_estimation</span><span class="p">.</span><span class="n">est</span><span class="p">[</span> <span class="sh">'</span><span class="s">coefficients</span><span class="sh">'</span> <span class="p">].</span><span class="n">iloc</span><span class="p">[</span> <span class="mi">2</span><span class="p">:,</span> <span class="p">:].</span><span class="nf">to_numpy</span><span class="p">()</span>    <span class="c1"># Get "X" coefficients 
</span>    <span class="n">SX_IDs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span> <span class="n">coef_array</span> <span class="o">!=</span> <span class="mi">0</span> <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># In case all X coefficients are zero, then regress Y on D
</span>    <span class="k">if</span> <span class="nf">sum</span><span class="p">(</span><span class="n">SX_IDs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span> 
        <span class="n">naive_coef</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span> <span class="n">Y</span> <span class="p">,</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">D</span><span class="p">)</span> <span class="p">).</span><span class="nf">fit</span><span class="p">().</span><span class="nf">summary2</span><span class="p">().</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span> <span class="p">]</span> 

    <span class="c1"># Otherwise, then regress Y on X and D (but only in the selected coefficients)
</span>    <span class="k">elif</span> <span class="nf">sum</span><span class="p">(</span> <span class="n">SX_IDs</span> <span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span>
        <span class="n">X_D</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span> <span class="n">D</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">SX_IDs</span> <span class="p">]</span> <span class="p">)</span> <span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">)</span>
        <span class="n">naive_coef</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span> <span class="n">Y</span> <span class="p">,</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span> <span class="n">X_D</span> <span class="p">)</span> <span class="p">).</span><span class="nf">fit</span><span class="p">().</span><span class="nf">summary2</span><span class="p">().</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="c1"># In both cases we save D coefficient
</span>        
    <span class="c1"># Regress residuals. 
</span>    <span class="n">resY</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="p">.</span><span class="nf">rlasso</span><span class="p">(</span> <span class="n">X</span> <span class="p">,</span> <span class="n">Y</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="bp">False</span> <span class="p">).</span><span class="n">est</span><span class="p">[</span> <span class="sh">'</span><span class="s">residuals</span><span class="sh">'</span> <span class="p">]</span>
    <span class="n">resD</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="p">.</span><span class="nf">rlasso</span><span class="p">(</span> <span class="n">X</span> <span class="p">,</span> <span class="n">D</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="bp">False</span> <span class="p">).</span><span class="n">est</span><span class="p">[</span> <span class="sh">'</span><span class="s">residuals</span><span class="sh">'</span> <span class="p">]</span>
    <span class="n">orthogonal_coef</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span> <span class="n">resY</span> <span class="p">,</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span> <span class="n">resD</span> <span class="p">)</span> <span class="p">).</span><span class="nf">fit</span><span class="p">().</span><span class="nf">summary2</span><span class="p">().</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">naive_coef</span><span class="p">,</span> <span class="n">orthogonal_coef</span>
</code></pre></div></div> <p>Then we define a function that runs the simulation on its enterity, using parallel computing and the function we previously defined.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_simulation</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="k">with</span> <span class="nc">Pool</span><span class="p">()</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="n">simulate_once</span><span class="p">,</span> <span class="nf">range</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
    <span class="n">Naive</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">])</span>
    <span class="n">Orthogonal</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">Naive</span><span class="p">,</span> <span class="n">Orthogonal</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Orto_breaks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">Naive_breaks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div> <p>Next we run the simulations with 100, 1000, and 10000 iterations and plot the histograms for the Naive and Orthogonal estimations</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Bs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">]</span>

<span class="k">for</span> <span class="n">B</span> <span class="ow">in</span> <span class="n">Bs</span><span class="p">:</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="n">Naive</span><span class="p">,</span> <span class="n">Orthogonal</span> <span class="o">=</span> <span class="nf">run_simulation</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Calculate elapsed time
</span>    
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">tight_layout</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span><span class="n">Orthogonal</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">Orto_breaks</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightblue</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span><span class="n">Naive</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">Naive_breaks</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightblue</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">Orthogonal</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">darkblue</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">Naive</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">darkblue</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">Orthogonal</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Average estimated effect</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">Naive</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Average estimated effect</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True Effect</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">True Effect</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">title</span><span class="p">.</span><span class="nf">set_text</span><span class="p">(</span><span class="sh">'</span><span class="s">Orthogonal estimation</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">title</span><span class="p">.</span><span class="nf">set_text</span><span class="p">(</span><span class="sh">'</span><span class="s">Naive estimation</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Treatment Effect</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Estimated Treatment Effect</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">get_legend_handles_labels</span><span class="p">()</span>
    <span class="n">fig</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">handles</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">lower center</span><span class="sh">'</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Simulation with </span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="s"> iterations</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Time taken for </span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="s"> iteration simulation: </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p3_output_17_0-480.webp 480w,/assets/img/p3_output_17_0-800.webp 800w,/assets/img/p3_output_17_0-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p3_output_17_0.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Time taken for 100 iteration simulation: 11.90 seconds
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p3_output_17_2-480.webp 480w,/assets/img/p3_output_17_2-800.webp 800w,/assets/img/p3_output_17_2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p3_output_17_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Time taken for 1000 iteration simulation: 79.43 seconds
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p3_output_17_4-480.webp 480w,/assets/img/p3_output_17_4-800.webp 800w,/assets/img/p3_output_17_4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p3_output_17_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Time taken for 10000 iteration simulation: 906.26 seconds
</code></pre></div></div> <p>We can se that the orthogonal estimation yields on average a coeficient more centered on the true effect than the naive estimation. This method of estimation that utilizes the residuals of lasso regresion and helps reduce bias more efficiently than the naive estimation method. This is because it leverages the properties explained on the begining of this notebook rather than just controlling for a relevant set of covariates which may induce endogeneity.</p> <p>We have used parallel computing because it is supposed to allow us to achieve better processing times. It can significantly lower the running time of computations due to its ability to distribute the workload across multiple processing units.</p> <p>As an example, we can see how long it would have taken to run the simulation with 1000 iteration if we had not utilized parallel computing.</p> <p>Without parallel computing</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">Naive</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span> <span class="n">B</span> <span class="p">)</span>
<span class="n">Orthogonal</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span> <span class="n">B</span> <span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span> <span class="n">B</span> <span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="p">)</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">p</span> <span class="p">,</span> <span class="mi">1</span> <span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="p">)</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">p</span> <span class="p">,</span> <span class="mi">1</span> <span class="p">)</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sd</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span> <span class="n">mean</span> <span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">p</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="p">)</span>

    <span class="n">D</span> <span class="o">=</span> <span class="p">(</span> <span class="n">X</span> <span class="o">@</span> <span class="n">gamma</span> <span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span> <span class="n">mean</span> <span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1</span> <span class="p">)</span><span class="o">/</span><span class="mi">4</span> <span class="c1"># We reshape because in r when we sum a vecto with a matrix it sum by column
</span>    
    <span class="c1"># DGP 
</span>    <span class="n">Y</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="n">D</span> <span class="o">+</span> <span class="p">(</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta</span> <span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span> <span class="n">mean</span> <span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="p">).</span><span class="nf">reshape</span><span class="p">(</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1</span> <span class="p">)</span>

    <span class="c1"># single selection method
</span>    <span class="n">r_lasso_estimation</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="p">.</span><span class="nf">rlasso</span><span class="p">(</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span> <span class="n">D</span> <span class="p">,</span> <span class="n">X</span> <span class="p">)</span> <span class="p">,</span> <span class="n">axis</span>  <span class="o">=</span>  <span class="mi">1</span> <span class="p">)</span> <span class="p">,</span> <span class="n">Y</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="bp">True</span> <span class="p">)</span> <span class="c1"># Regress main equation by lasso
</span>
    <span class="n">coef_array</span> <span class="o">=</span> <span class="n">r_lasso_estimation</span><span class="p">.</span><span class="n">est</span><span class="p">[</span> <span class="sh">'</span><span class="s">coefficients</span><span class="sh">'</span> <span class="p">].</span><span class="n">iloc</span><span class="p">[</span> <span class="mi">2</span><span class="p">:,</span> <span class="p">:].</span><span class="nf">to_numpy</span><span class="p">()</span>    <span class="c1"># Get "X" coefficients 
</span>
    <span class="n">SX_IDs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span> <span class="n">coef_array</span> <span class="o">!=</span> <span class="mi">0</span> <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># In case all X coefficients are zero, then regress Y on D
</span>    <span class="k">if</span> <span class="nf">sum</span><span class="p">(</span><span class="n">SX_IDs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span> 
        <span class="n">Naive</span><span class="p">[</span> <span class="n">i</span> <span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span> <span class="n">Y</span> <span class="p">,</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">D</span><span class="p">)</span> <span class="p">).</span><span class="nf">fit</span><span class="p">().</span><span class="nf">summary2</span><span class="p">().</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span> <span class="p">]</span> 

    <span class="c1"># Otherwise, then regress Y on X and D (but only in the selected coefficients)
</span>    <span class="k">elif</span> <span class="nf">sum</span><span class="p">(</span> <span class="n">SX_IDs</span> <span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span>
        <span class="n">X_D</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span> <span class="n">D</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">SX_IDs</span> <span class="p">]</span> <span class="p">)</span> <span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">)</span>
        <span class="n">Naive</span><span class="p">[</span> <span class="n">i</span> <span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span> <span class="n">Y</span> <span class="p">,</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span> <span class="n">X_D</span> <span class="p">)</span> <span class="p">).</span><span class="nf">fit</span><span class="p">().</span><span class="nf">summary2</span><span class="p">().</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="c1"># In both cases we save D coefficient
</span>        
    <span class="c1"># Regress residuals. 
</span>    <span class="n">resY</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="p">.</span><span class="nf">rlasso</span><span class="p">(</span> <span class="n">X</span> <span class="p">,</span> <span class="n">Y</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="bp">False</span> <span class="p">).</span><span class="n">est</span><span class="p">[</span> <span class="sh">'</span><span class="s">residuals</span><span class="sh">'</span> <span class="p">]</span>
    <span class="n">resD</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="p">.</span><span class="nf">rlasso</span><span class="p">(</span> <span class="n">X</span> <span class="p">,</span> <span class="n">D</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="bp">False</span> <span class="p">).</span><span class="n">est</span><span class="p">[</span> <span class="sh">'</span><span class="s">residuals</span><span class="sh">'</span> <span class="p">]</span>
    <span class="n">Orthogonal</span><span class="p">[</span> <span class="n">i</span> <span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span> <span class="n">resY</span> <span class="p">,</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span> <span class="n">resD</span> <span class="p">)</span> <span class="p">).</span><span class="nf">fit</span><span class="p">().</span><span class="nf">summary2</span><span class="p">().</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Calculate elapsed time
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Time taken for </span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="s"> iteration simulation without multiprocessing: </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Time taken for 1000 iteration simulation without multiprocessing: 488.92 seconds
</code></pre></div></div> <p>We can see that if we were to not use parallel computing, the processing time would be higher. It took 488 seconds to achieve what we achieved in 79.</p> <h3 id="22-double-lasso---using-school-data">2.2. Double Lasso - Using School data</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Libraries
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="n">statsmodels.formula.api</span> <span class="k">as</span> <span class="n">smf</span>
<span class="kn">from</span> <span class="n">stargazer.stargazer</span> <span class="kn">import</span> <span class="n">Stargazer</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span>
</code></pre></div></div> <h4 id="221-preprocessing-data">2.2.1. Preprocessing data</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Read csv file
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">./data/bruhn2016.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>outcome.test.score</th> <th>treatment</th> <th>school</th> <th>is.female</th> <th>mother.attended.secondary.school</th> <th>father.attened.secondary.school</th> <th>failed.at.least.one.school.year</th> <th>family.receives.cash.transfer</th> <th>has.computer.with.internet.at.home</th> <th>is.unemployed</th> <th>has.some.form.of.income</th> <th>saves.money.for.future.purchases</th> <th>intention.to.save.index</th> <th>makes.list.of.expenses.every.month</th> <th>negotiates.prices.or.payment.methods</th> <th>financial.autonomy.index</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>47.367374</td> <td>0</td> <td>17018390</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>1.0</td> <td>1.0</td> <td>0.0</td> <td>29.0</td> <td>0.0</td> <td>1.0</td> <td>52.0</td> </tr> <tr> <th>1</th> <td>58.176758</td> <td>1</td> <td>33002614</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>41.0</td> <td>0.0</td> <td>0.0</td> <td>27.0</td> </tr> <tr> <th>2</th> <td>56.671661</td> <td>1</td> <td>35002914</td> <td>1.0</td> <td>1.0</td> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>48.0</td> <td>0.0</td> <td>1.0</td> <td>56.0</td> </tr> <tr> <th>3</th> <td>29.079376</td> <td>0</td> <td>35908915</td> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>42.0</td> <td>0.0</td> <td>0.0</td> <td>27.0</td> </tr> <tr> <th>4</th> <td>49.563534</td> <td>1</td> <td>33047324</td> <td>1.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>0.0</td> <td>1.0</td> <td>0.0</td> <td>1.0</td> <td>0.0</td> <td>50.0</td> <td>0.0</td> <td>1.0</td> <td>31.0</td> </tr> </tbody> </table> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Drop missing values, we lose 5077 values (from 17299 to 12222 rows)
</span><span class="n">df</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span> <span class="p">,</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['outcome.test.score', 'treatment', 'school', 'is.female',
       'mother.attended.secondary.school', 'father.attened.secondary.school',
       'failed.at.least.one.school.year', 'family.receives.cash.transfer',
       'has.computer.with.internet.at.home', 'is.unemployed',
       'has.some.form.of.income', 'saves.money.for.future.purchases',
       'intention.to.save.index', 'makes.list.of.expenses.every.month',
       'negotiates.prices.or.payment.methods', 'financial.autonomy.index'],
      dtype='object')
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dependent_vars</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">outcome.test.score</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">intention.to.save.index</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">negotiates.prices.or.payment.methods</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">has.some.form.of.income</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">makes.list.of.expenses.every.month</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">financial.autonomy.index</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">saves.money.for.future.purchases</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">is.unemployed</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p>For Lasso regressions, we split the data into train and test data, and standarize the covariates matrix</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Train test split
</span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">dependent_vars</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">dependent_vars</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">T_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span><span class="p">]</span>
<span class="n">T_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span><span class="p">]</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Standarize X data
</span><span class="n">scale</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>

<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">scale</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">scale</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">X_test</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">X_test_scaled</span><span class="p">]).</span><span class="nf">sort_index</span><span class="p">()</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">T_train</span><span class="p">,</span> <span class="n">T_test</span><span class="p">]).</span><span class="nf">sort_index</span><span class="p">()</span>
</code></pre></div></div> <h4 id="222-regressions">2.2.2. Regressions</h4> <h5 id="a-ols">a. OLS</h5> <p>From 1 - 3 regression: measures treatment impact on <strong>student financial proficiency</strong></p> <p>From 4 - 6 regression: measures treatment impact on <strong>student savings behavior and attitudes</strong></p> <p>From 7 - 9 regression: measures treatment impact on <strong>student money management behavior and attitudes</strong></p> <p>From 10 - 12 regression: measures treatment impact on <strong>student entrepreneurship and work outcomes</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Rgeressions with "Student Financial Proficiency" as dependet variable
</span><span class="n">ols_score_1</span>      <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">outcome.test.score</span><span class="sh">"</span><span class="s">) ~ treatment</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">ols_score_2</span>      <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">outcome.test.score</span><span class="sh">"</span><span class="s">) ~ treatment + school + Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">ols_score_3</span>      <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">outcome.test.score</span><span class="sh">"</span><span class="s">) ~ treatment + school + Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">is.female</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">mother.attended.secondary.school</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">father.attened.secondary.school</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">family.receives.cash.transfer</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">has.computer.with.internet.at.home</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>

<span class="c1"># Rgeressions with "Intention to save index" as dependet variable
</span><span class="n">ols_saving_1</span>     <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">intention.to.save.index</span><span class="sh">"</span><span class="s">) ~ treatment</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">ols_saving_2</span>     <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">intention.to.save.index</span><span class="sh">"</span><span class="s">) ~ treatment + school + Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">ols_saving_3</span>     <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">intention.to.save.index</span><span class="sh">"</span><span class="s">) ~ treatment + school + Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">is.female</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">mother.attended.secondary.school</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">father.attened.secondary.school</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">family.receives.cash.transfer</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">has.computer.with.internet.at.home</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>

<span class="c1"># Rgeressions with "Negotiates prices or payment methods" as dependet variable
</span><span class="n">ols_negotiates_1</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">negotiates.prices.or.payment.methods</span><span class="sh">"</span><span class="s">) ~ treatment</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">ols_negotiates_2</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">negotiates.prices.or.payment.methods</span><span class="sh">"</span><span class="s">) ~ treatment + school + Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">ols_negotiates_3</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">negotiates.prices.or.payment.methods</span><span class="sh">"</span><span class="s">) ~ treatment + school + Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">is.female</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">mother.attended.secondary.school</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">father.attened.secondary.school</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">family.receives.cash.transfer</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">has.computer.with.internet.at.home</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>

<span class="c1"># Rgeressions with "Has some form of income" as dependet variable
</span><span class="n">ols_manage_1</span>     <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">has.some.form.of.income</span><span class="sh">"</span><span class="s">) ~ treatment</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">ols_manage_2</span>     <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">has.some.form.of.income</span><span class="sh">"</span><span class="s">) ~ treatment + school + Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">ols_manage_3</span>     <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">has.some.form.of.income</span><span class="sh">"</span><span class="s">) ~ treatment + school + Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">is.female</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">mother.attended.secondary.school</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">father.attened.secondary.school</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">family.receives.cash.transfer</span><span class="sh">"</span><span class="s">) + Q(</span><span class="sh">"</span><span class="s">has.computer.with.internet.at.home</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>

<span class="c1"># Show parameters in table
</span><span class="n">st</span> <span class="o">=</span> <span class="nc">Stargazer</span><span class="p">([</span><span class="n">ols_score_1</span><span class="p">,</span> <span class="n">ols_score_2</span><span class="p">,</span> <span class="n">ols_score_3</span><span class="p">,</span> <span class="n">ols_saving_1</span><span class="p">,</span> <span class="n">ols_saving_2</span><span class="p">,</span> <span class="n">ols_saving_3</span><span class="p">,</span> <span class="n">ols_negotiates_1</span><span class="p">,</span> <span class="n">ols_negotiates_2</span><span class="p">,</span> <span class="n">ols_negotiates_3</span><span class="p">,</span> <span class="n">ols_manage_1</span><span class="p">,</span> <span class="n">ols_manage_2</span><span class="p">,</span> <span class="n">ols_manage_3</span><span class="p">])</span>
<span class="n">st</span><span class="p">.</span><span class="nf">custom_columns</span><span class="p">([</span><span class="sh">"</span><span class="s">Dependent var 1: Student Financial Proficiency</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Dependent var 2: Intention to save index</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Dependent var 3: Negotiates prices or payment methods</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Dependent var 4: Has some form of income</span><span class="sh">"</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">st</span><span class="p">.</span><span class="nf">rename_covariates</span><span class="p">({</span><span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">failed.at.least.one.school.year</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Failed at least one school year</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">is.female</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Female</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">father.attened.secondary.school</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Father attended secondary school</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">Family.receives.cash.transfer</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Family receives cash transfer</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Q(</span><span class="sh">"</span><span class="s">has.computer.with.internet.at.home</span><span class="sh">"</span><span class="s">)</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Has computer with internet at home</span><span class="sh">'</span><span class="p">})</span>
<span class="n">st</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
</code></pre></div></div> <table style="text-align:center"> <tr><td colspan="13" style="border-bottom: 1px solid black"></td></tr> <tr><td style="text-align:left"></td></tr> <tr> <td></td> <td colspan="3">Dependent var 1: Student Financial Proficiency</td> <td colspan="3">Dependent var 2: Intention to save index</td> <td colspan="3">Dependent var 3: Negotiates prices or payment methods</td> <td colspan="3">Dependent var 4: Has some form of income</td> </tr> <tr> <td style="text-align:left"></td> <td>(1)</td> <td>(2)</td> <td>(3)</td> <td>(4)</td> <td>(5)</td> <td>(6)</td> <td>(7)</td> <td>(8)</td> <td>(9)</td> <td>(10)</td> <td>(11)</td> <td>(12)</td> </tr> <tr><td colspan="13" style="border-bottom: 1px solid black"></td></tr> <tr> <td style="text-align:left">Intercept</td> <td>57.591<sup>***</sup> </td> <td>59.377<sup>***</sup> </td> <td>58.860<sup>***</sup> </td> <td>49.016<sup>***</sup> </td> <td>46.725<sup>***</sup> </td> <td>46.603<sup>***</sup> </td> <td>0.763<sup>***</sup> </td> <td>0.856<sup>***</sup> </td> <td>0.855<sup>***</sup> </td> <td>0.639<sup>***</sup> </td> <td>0.534<sup>***</sup> </td> <td>0.609<sup>***</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td>(0.187)</td> <td>(0.556)</td> <td>(0.675)</td> <td>(0.240)</td> <td>(0.728)</td> <td>(0.890)</td> <td>(0.006)</td> <td>(0.017)</td> <td>(0.020)</td> <td>(0.006)</td> <td>(0.019)</td> <td>(0.023)</td> </tr> <tr> <td style="text-align:left">Failed at least one school year</td> <td></td> <td>-7.218<sup>***</sup> </td> <td>-6.652<sup>***</sup> </td> <td></td> <td>-3.614<sup>***</sup> </td> <td>-3.315<sup>***</sup> </td> <td></td> <td>0.024<sup>***</sup> </td> <td>0.013<sup></sup> </td> <td></td> <td>0.005<sup></sup> </td> <td>0.006<sup></sup> </td> </tr> <tr> <td style="text-align:left"></td> <td></td> <td>(0.288)</td> <td>(0.289)</td> <td></td> <td>(0.377)</td> <td>(0.381)</td> <td></td> <td>(0.009)</td> <td>(0.009)</td> <td></td> <td>(0.010)</td> <td>(0.010)</td> </tr> <tr> <td style="text-align:left">Q("family.receives.cash.transfer")</td> <td></td> <td></td> <td>-1.837<sup>***</sup> </td> <td></td> <td></td> <td>-1.189<sup>***</sup> </td> <td></td> <td></td> <td>0.028<sup>***</sup> </td> <td></td> <td></td> <td>-0.027<sup>***</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td></td> <td></td> <td>(0.283)</td> <td></td> <td></td> <td>(0.374)</td> <td></td> <td></td> <td>(0.009)</td> <td></td> <td></td> <td>(0.010)</td> </tr> <tr> <td style="text-align:left">Father attended secondary school</td> <td></td> <td></td> <td>0.875<sup>***</sup> </td> <td></td> <td></td> <td>-0.213<sup></sup> </td> <td></td> <td></td> <td>-0.012<sup></sup> </td> <td></td> <td></td> <td>0.021<sup>**</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td></td> <td></td> <td>(0.298)</td> <td></td> <td></td> <td>(0.392)</td> <td></td> <td></td> <td>(0.009)</td> <td></td> <td></td> <td>(0.010)</td> </tr> <tr> <td style="text-align:left">Has computer with internet at home</td> <td></td> <td></td> <td>-0.505<sup>*</sup> </td> <td></td> <td></td> <td>-0.276<sup></sup> </td> <td></td> <td></td> <td>0.024<sup>***</sup> </td> <td></td> <td></td> <td>-0.035<sup>***</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td></td> <td></td> <td>(0.281)</td> <td></td> <td></td> <td>(0.371)</td> <td></td> <td></td> <td>(0.009)</td> <td></td> <td></td> <td>(0.010)</td> </tr> <tr> <td style="text-align:left">Female</td> <td></td> <td></td> <td>2.943<sup>***</sup> </td> <td></td> <td></td> <td>1.403<sup>***</sup> </td> <td></td> <td></td> <td>-0.069<sup>***</sup> </td> <td></td> <td></td> <td>-0.051<sup>***</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td></td> <td></td> <td>(0.257)</td> <td></td> <td></td> <td>(0.339)</td> <td></td> <td></td> <td>(0.008)</td> <td></td> <td></td> <td>(0.009)</td> </tr> <tr> <td style="text-align:left">Q("mother.attended.secondary.school")</td> <td></td> <td></td> <td>0.968<sup>***</sup> </td> <td></td> <td></td> <td>1.192<sup>***</sup> </td> <td></td> <td></td> <td>0.001<sup></sup> </td> <td></td> <td></td> <td>0.013<sup></sup> </td> </tr> <tr> <td style="text-align:left"></td> <td></td> <td></td> <td>(0.295)</td> <td></td> <td></td> <td>(0.388)</td> <td></td> <td></td> <td>(0.009)</td> <td></td> <td></td> <td>(0.010)</td> </tr> <tr> <td style="text-align:left">school</td> <td></td> <td>0.000<sup></sup> </td> <td>-0.000<sup>**</sup> </td> <td></td> <td>0.000<sup>***</sup> </td> <td>0.000<sup>***</sup> </td> <td></td> <td>-0.000<sup>***</sup> </td> <td>-0.000<sup>***</sup> </td> <td></td> <td>0.000<sup>***</sup> </td> <td>0.000<sup>***</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td></td> <td>(0.000)</td> <td>(0.000)</td> <td></td> <td>(0.000)</td> <td>(0.000)</td> <td></td> <td>(0.000)</td> <td>(0.000)</td> <td></td> <td>(0.000)</td> <td>(0.000)</td> </tr> <tr> <td style="text-align:left">treatment</td> <td>4.216<sup>***</sup> </td> <td>4.392<sup>***</sup> </td> <td>4.325<sup>***</sup> </td> <td>-0.070<sup></sup> </td> <td>-0.005<sup></sup> </td> <td>-0.032<sup></sup> </td> <td>0.001<sup></sup> </td> <td>0.001<sup></sup> </td> <td>0.003<sup></sup> </td> <td>0.017<sup>**</sup> </td> <td>0.016<sup>*</sup> </td> <td>0.018<sup>**</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td>(0.261)</td> <td>(0.255)</td> <td>(0.253)</td> <td>(0.335)</td> <td>(0.334)</td> <td>(0.333)</td> <td>(0.008)</td> <td>(0.008)</td> <td>(0.008)</td> <td>(0.009)</td> <td>(0.009)</td> <td>(0.009)</td> </tr> <td colspan="13" style="border-bottom: 1px solid black"></td> <tr> <td style="text-align: left">Observations</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> <td>12222</td> </tr> <tr> <td style="text-align: left">R<sup>2</sup> </td> <td>0.021</td> <td>0.069</td> <td>0.086</td> <td>0.000</td> <td>0.009</td> <td>0.013</td> <td>0.000</td> <td>0.004</td> <td>0.012</td> <td>0.000</td> <td>0.003</td> <td>0.011</td> </tr> <tr> <td style="text-align: left">Adjusted R<sup>2</sup> </td> <td>0.021</td> <td>0.068</td> <td>0.085</td> <td>-0.000</td> <td>0.009</td> <td>0.012</td> <td>-0.000</td> <td>0.004</td> <td>0.012</td> <td>0.000</td> <td>0.003</td> <td>0.010</td> </tr> <tr> <td style="text-align: left">Residual Std. Error</td> <td>14.432 (df=12220)</td> <td>14.076 (df=12218)</td> <td>13.949 (df=12213)</td> <td>18.506 (df=12220)</td> <td>18.421 (df=12218)</td> <td>18.393 (df=12213)</td> <td>0.425 (df=12220)</td> <td>0.424 (df=12218)</td> <td>0.423 (df=12213)</td> <td>0.478 (df=12220)</td> <td>0.477 (df=12218)</td> <td>0.475 (df=12213)</td> </tr> <tr> <td style="text-align: left">F Statistic</td> <td>260.547<sup>***</sup> (df=1; 12220)</td> <td>300.463<sup>***</sup> (df=3; 12218)</td> <td>143.315<sup>***</sup> (df=8; 12213)</td> <td>0.043<sup></sup> (df=1; 12220)</td> <td>38.533<sup>***</sup> (df=3; 12218)</td> <td>19.812<sup>***</sup> (df=8; 12213)</td> <td>0.018<sup></sup> (df=1; 12220)</td> <td>16.352<sup>***</sup> (df=3; 12218)</td> <td>18.841<sup>***</sup> (df=8; 12213)</td> <td>3.843<sup>**</sup> (df=1; 12220)</td> <td>12.839<sup>***</sup> (df=3; 12218)</td> <td>16.603<sup>***</sup> (df=8; 12213)</td> </tr> <tr><td colspan="13" style="border-bottom: 1px solid black"></td></tr> <tr> <td style="text-align: left">Note:</td> <td colspan="12" style="text-align: right"> <sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td> </tr> </table> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Save the ITT beta and the confidence intervals
</span><span class="n">beta_OLS</span> <span class="o">=</span> <span class="n">ols_score_3</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span><span class="p">]</span>
<span class="n">conf_int_OLS</span> <span class="o">=</span> <span class="n">ols_score_3</span><span class="p">.</span><span class="nf">conf_int</span><span class="p">().</span><span class="n">loc</span><span class="p">[</span><span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <h5 id="b-double-lasso-using-cross-validation">b. Double Lasso using cross validation</h5> <p>We use the first dependent variable (Student Financial Proficiency)</p> <p>Step 1: We ran Lasso regression of <em>Y</em> (student financial proficiency) on <em>X</em>, and <em>T</em> (treatment) on <em>X</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lasso_CV_yX</span> <span class="o">=</span> <span class="nc">LassoCV</span><span class="p">(</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">),</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">)</span>
<span class="n">lasso_CV_yX</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">[</span><span class="sh">'</span><span class="s">outcome.test.score</span><span class="sh">'</span><span class="p">])</span>

<span class="n">lasso_CV_lambda</span> <span class="o">=</span> <span class="n">lasso_CV_yX</span><span class="p">.</span><span class="n">alpha_</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Mejor lambda: </span><span class="si">{</span><span class="n">lasso_CV_lambda</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Mejor lambda: 0.0001
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Estimate y predictions with all X
</span><span class="n">y_pred_yX</span> <span class="o">=</span> <span class="n">lasso_CV_yX</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lasso_CV_TX</span> <span class="o">=</span> <span class="nc">LassoCV</span><span class="p">(</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">),</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">)</span>
<span class="n">lasso_CV_TX</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">T_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lasso_CV_TX</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="n">lasso_CV_lambda</span> <span class="o">=</span> <span class="n">lasso_CV_TX</span><span class="p">.</span><span class="n">alpha_</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Mejor lambda: </span><span class="si">{</span><span class="n">lasso_CV_lambda</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Mejor lambda: 0.0011
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Estimate T predictions with all X
</span><span class="n">y_pred_TX</span> <span class="o">=</span> <span class="n">lasso_CV_TX</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
</code></pre></div></div> <p>Step 2: Obtain the resulting residuals</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">res_yX</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="sh">'</span><span class="s">outcome.test.score</span><span class="sh">'</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_pred_yX</span>
<span class="n">res_TX</span> <span class="o">=</span> <span class="n">T</span> <span class="o">-</span> <span class="n">y_pred_TX</span>
</code></pre></div></div> <p>Step 3: We run the least squares of res_yX on res_TX</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ols_score_b</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">res_yX ~ res_TX</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>

<span class="c1"># Show parameters in table
</span><span class="n">st</span> <span class="o">=</span> <span class="nc">Stargazer</span><span class="p">([</span><span class="n">ols_score_b</span><span class="p">])</span>
<span class="n">st</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
</code></pre></div></div> <table style="text-align:center"> <tr><td colspan="2" style="border-bottom: 1px solid black"></td></tr> <tr> <td style="text-align:left"></td> <td colspan="1"><em>Dependent variable: res_yX</em></td> </tr> <tr><td style="text-align:left"></td></tr> <tr> <td style="text-align:left"></td> <td>(1)</td> </tr> <tr><td colspan="2" style="border-bottom: 1px solid black"></td></tr> <tr> <td style="text-align:left">Intercept</td> <td>0.033<sup></sup> </td> </tr> <tr> <td style="text-align:left"></td> <td>(0.126)</td> </tr> <tr> <td style="text-align:left">res_TX</td> <td>4.324<sup>***</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td>(0.253)</td> </tr> <td colspan="2" style="border-bottom: 1px solid black"></td> <tr> <td style="text-align: left">Observations</td> <td>12222</td> </tr> <tr> <td style="text-align: left">R<sup>2</sup> </td> <td>0.023</td> </tr> <tr> <td style="text-align: left">Adjusted R<sup>2</sup> </td> <td>0.023</td> </tr> <tr> <td style="text-align: left">Residual Std. Error</td> <td>13.945 (df=12220)</td> </tr> <tr> <td style="text-align: left">F Statistic</td> <td>292.956<sup>***</sup> (df=1; 12220)</td> </tr> <tr><td colspan="2" style="border-bottom: 1px solid black"></td></tr> <tr> <td style="text-align: left">Note:</td> <td colspan="1" style="text-align: right"> <sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td> </tr> </table> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Save the ITT beta and the confidence intervals
</span><span class="n">beta_DL_CV</span> <span class="o">=</span> <span class="n">ols_score_b</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">res_TX</span><span class="sh">'</span><span class="p">]</span>
<span class="n">conf_int_DL_CV</span> <span class="o">=</span> <span class="n">ols_score_b</span><span class="p">.</span><span class="nf">conf_int</span><span class="p">().</span><span class="n">loc</span><span class="p">[</span><span class="sh">'</span><span class="s">res_TX</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <h5 id="c-double-lasso-using-theoretical-lambda">c. Double Lasso using theoretical lambda</h5> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># !pip install multiprocess
# !pip install pyreadr
# !git clone https://github.com/maxhuppertz/hdmpy.git
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">sys</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">./hdmpy</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># We wrap the package so that it has the familiar sklearn API
</span><span class="kn">import</span> <span class="n">hdmpy</span>
<span class="kn">from</span> <span class="n">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">clone</span>

<span class="k">class</span> <span class="nc">RLasso</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">post</span> <span class="o">=</span> <span class="n">post</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rlasso_</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="p">.</span><span class="nf">rlasso</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">post</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">post</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">rlasso_</span><span class="p">.</span><span class="n">est</span><span class="p">[</span><span class="sh">'</span><span class="s">beta</span><span class="sh">'</span><span class="p">]).</span><span class="nf">flatten</span><span class="p">()</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">rlasso_</span><span class="p">.</span><span class="n">est</span><span class="p">[</span><span class="sh">'</span><span class="s">intercept</span><span class="sh">'</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">nsel</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">sum</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">rlasso_</span><span class="p">.</span><span class="n">est</span><span class="p">[</span><span class="sh">'</span><span class="s">beta</span><span class="sh">'</span><span class="p">]).</span><span class="nf">flatten</span><span class="p">()</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">))</span>

<span class="n">lasso_model</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="nc">RLasso</span><span class="p">(</span><span class="n">post</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p>Step 1:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Estimate y predictions with all X
</span><span class="n">y_pred_yX</span> <span class="o">=</span> <span class="nf">lasso_model</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="sh">'</span><span class="s">outcome.test.score</span><span class="sh">'</span><span class="p">]).</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Estimate T predictions with all X
</span><span class="n">y_pred_TX</span> <span class="o">=</span> <span class="nf">lasso_model</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">T</span><span class="p">).</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
</code></pre></div></div> <p>Step 2:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">res_yX</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="sh">'</span><span class="s">outcome.test.score</span><span class="sh">'</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_pred_yX</span>
<span class="n">res_TX</span> <span class="o">=</span> <span class="n">T</span> <span class="o">-</span> <span class="n">y_pred_TX</span>
</code></pre></div></div> <p>Step 3:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lasso_hdm_score</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">.</span><span class="nf">from_formula</span><span class="p">(</span><span class="sh">'</span><span class="s">res_yX ~ res_TX</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>

<span class="c1"># Show parameters in table
</span><span class="n">st</span> <span class="o">=</span> <span class="nc">Stargazer</span><span class="p">([</span><span class="n">lasso_hdm_score</span><span class="p">])</span>
<span class="n">st</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
</code></pre></div></div> <table style="text-align:center"> <tr><td colspan="2" style="border-bottom: 1px solid black"></td></tr> <tr> <td style="text-align:left"></td> <td colspan="1"><em>Dependent variable: res_yX</em></td> </tr> <tr><td style="text-align:left"></td></tr> <tr> <td style="text-align:left"></td> <td>(1)</td> </tr> <tr><td colspan="2" style="border-bottom: 1px solid black"></td></tr> <tr> <td style="text-align:left">Intercept</td> <td>0.000<sup></sup> </td> </tr> <tr> <td style="text-align:left"></td> <td>(0.126)</td> </tr> <tr> <td style="text-align:left">res_TX</td> <td>4.316<sup>***</sup> </td> </tr> <tr> <td style="text-align:left"></td> <td>(0.253)</td> </tr> <td colspan="2" style="border-bottom: 1px solid black"></td> <tr> <td style="text-align: left">Observations</td> <td>12222</td> </tr> <tr> <td style="text-align: left">R<sup>2</sup> </td> <td>0.023</td> </tr> <tr> <td style="text-align: left">Adjusted R<sup>2</sup> </td> <td>0.023</td> </tr> <tr> <td style="text-align: left">Residual Std. Error</td> <td>13.953 (df=12220)</td> </tr> <tr> <td style="text-align: left">F Statistic</td> <td>291.837<sup>***</sup> (df=1; 12220)</td> </tr> <tr><td colspan="2" style="border-bottom: 1px solid black"></td></tr> <tr> <td style="text-align: left">Note:</td> <td colspan="1" style="text-align: right"> <sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td> </tr> </table> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Save the ITT beta and the confidence intervals
</span><span class="n">beta_DL_theo</span> <span class="o">=</span> <span class="n">lasso_hdm_score</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">res_TX</span><span class="sh">'</span><span class="p">]</span>
<span class="n">conf_int_DL_theo</span> <span class="o">=</span> <span class="n">lasso_hdm_score</span><span class="p">.</span><span class="nf">conf_int</span><span class="p">().</span><span class="n">loc</span><span class="p">[</span><span class="sh">'</span><span class="s">res_TX</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <h5 id="d-double-lasso-using-partialling-out-method">d. Double Lasso using partialling out method</h5> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rlassoEffect</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="p">.</span><span class="nf">rlassoEffect</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="sh">'</span><span class="s">outcome.test.score</span><span class="sh">'</span><span class="p">],</span> <span class="n">T</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">partialling out</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rlassoEffect</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'alpha': 4.313441,
 'se': array([0.25271166]),
 't': array([17.06862565]),
 'pval': array([2.54111627e-65]),
 'coefficients': 4.313441,
 'coefficient': 4.313441,
 'coefficients_reg':                      0
 (Intercept)  59.769260
 x0            0.000000
 x1            1.511205
 x2            0.529423
 x3            0.461196
 x4           -2.878027
 x5           -0.857569
 x6            0.000000,
 'selection_index': array([[False],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False]]),
 'residuals': {'epsilon': array([[-10.04200277],
         [-31.30841071],
         [-15.13769394],
         ...,
         [-17.22383794],
         [ -3.93047339],
         [ -4.88461742]]),
  'v': array([[ 0.48682705],
         [-0.513173  ],
         [ 0.48682705],
         ...,
         [ 0.48682705],
         [-0.513173  ],
         [-0.513173  ]], dtype=float32)},
 'samplesize': 12222}
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">beta_part_out</span> <span class="o">=</span> <span class="n">rlassoEffect</span><span class="p">[</span><span class="sh">'</span><span class="s">coefficient</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">critical_value</span> <span class="o">=</span> <span class="mf">1.96</span>  <span class="c1"># For 95% confidence level
</span>
<span class="n">conf_int_part_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">beta_part_out</span> <span class="o">-</span> <span class="n">critical_value</span> <span class="o">*</span> <span class="n">rlassoEffect</span><span class="p">[</span><span class="sh">'</span><span class="s">se</span><span class="sh">'</span><span class="p">],</span> \
                     <span class="n">beta_part_out</span> <span class="o">+</span> <span class="n">critical_value</span> <span class="o">*</span> <span class="n">rlassoEffect</span><span class="p">[</span><span class="sh">'</span><span class="s">se</span><span class="sh">'</span><span class="p">]]</span>
</code></pre></div></div> <h4 id="results">Results</h4> <p>We found that the intention to treat effect (ITT) is very similar estimating with all 4 models (aproximately 4.3, with 95% of confidence). This could be because the ratio between the parameters and the number of observations p/n is small (8/12222 = 0.00065455735). In other words, we are not dealing with high dimensional data and the models from b. to d. will outperform the OLS when we are in the opposite scenario. In conclusion, we can say that the OLS model estimates the ITT just as good as the other models.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plotting the effect size with confidence intervals
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">errorbar</span><span class="p">(</span><span class="sh">'</span><span class="s">OLS</span><span class="sh">'</span><span class="p">,</span> <span class="n">beta_OLS</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">beta_OLS</span> <span class="o">-</span> <span class="n">conf_int_OLS</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conf_int_OLS</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">beta_OLS</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
             <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">errorbar</span><span class="p">(</span><span class="sh">'</span><span class="s">Double Lasso with CV</span><span class="sh">'</span><span class="p">,</span> <span class="n">beta_DL_CV</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">beta_DL_CV</span> <span class="o">-</span> <span class="n">conf_int_DL_CV</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conf_int_DL_CV</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">beta_DL_CV</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
             <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">errorbar</span><span class="p">(</span><span class="sh">'</span><span class="s">Double Lasso with theoretical lambda</span><span class="sh">'</span><span class="p">,</span> <span class="n">beta_DL_theo</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">beta_DL_theo</span> <span class="o">-</span> <span class="n">conf_int_DL_theo</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conf_int_DL_theo</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">beta_DL_theo</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
             <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">errorbar</span><span class="p">(</span><span class="sh">'</span><span class="s">Double Lasso with partialling out</span><span class="sh">'</span><span class="p">,</span> <span class="n">beta_part_out</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">beta_part_out</span> <span class="o">-</span> <span class="n">conf_int_part_out</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conf_int_part_out</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">beta_part_out</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
             <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Intention to treat effect on Student Financial Proficiency</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Beta and cofidence interval</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p3_output_72_0-480.webp 480w,/assets/img/p3_output_72_0-800.webp 800w,/assets/img/p3_output_72_0-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p3_output_72_0.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Matias Villalba. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>